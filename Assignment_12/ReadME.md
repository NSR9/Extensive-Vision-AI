# Assignment 12 - The Dawn of the Transformers:

## Problem Statement:

1. Implement that [Spatial Transformer Code](https://brsoff.github.io/tutorials/intermediate/spatial_transformer_tutorial.html) for CIFAR10 and submit. Must have proper readme and must be trained for 50 Epochs.
2. Describe using text and your drawn images, the classes in this [FILE](https://github.com/jeonsworld/ViT-pytorch/blob/main/models/modeling.py) (Links to an external site.):
 - Block
 - Embeddings
 - MLP
 - Attention
 - Encoder
 
## Solution:
A picture is worth a thousand words? It is not possible to fully describe a picture using words. But the papers tell us that an image worth 16×16 words. Image recognition using transformers was brought in by authors  in Natural Language Processing from the paper “[Attention all you need](https://arxiv.org/abs/1706.03762)”. In this paper, they didn’t modify the attention layers in the transformer adore. The most important trick they do is to break an image into small patches of image( perhaps 16×16 as in the title). This marked the birth of Computer Vision in the fields of transformers. 

The Most common two methods used  are:
- Spatial Transformers(STN's):
 - [Link to ReadME](https://github.com/NSR9/Extensive-Vision-AI/blob/main/Assignment_12/Spatial%20Transformation/ReadME.md)
 - [Link to Colab Notebook]()
 - [Link to Gthub ipynb Notebook]()
- Vision Transformers(ViT's):
 - [Link to ReadME](https://github.com/NSR9/Extensive-Vision-AI/blob/main/Assignment_12/Vision%20Transformers/ReadME.md)

## Contributors:
